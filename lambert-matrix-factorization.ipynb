{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import autograd.numpy.random as npr\n",
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "from autograd.extend import primitive, defvjp\n",
    "from autograd.misc.optimizers import adam\n",
    "import scipy.special.lambertw as lambertw_\n",
    "import autograd.scipy.stats.norm as norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "npr.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambertw(x):\n",
    "    if np.any(x < -1/np.e):\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return lambertw_(x,0).real\n",
    "    \n",
    "lambertw = primitive(lambertw)\n",
    "\n",
    "defvjp(lambertw, \n",
    "#            lambda ans, x: lambda g: g * ans/(x*(1+ans)),\n",
    "        lambda ans, x: lambda g:  g * 1./ (x + np.exp(ans)),\n",
    "        None \n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sample data\n",
    "N = 1000\n",
    "D = 50\n",
    "K = 10\n",
    "\n",
    "scale = 1.\n",
    "skew = -0.05\n",
    "theta_o = theta = npr.randn(N,K) \n",
    "beta_o = beta = npr.randn(D,K) \n",
    "\n",
    "loc = np.matmul(theta, beta.T)\n",
    "u = npr.randn(N,D)\n",
    "# z = u * scale + loc\n",
    "y = u * np.exp(skew * u) * scale + loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lambertw_routines(y):\n",
    "    \n",
    "    def skew_function(skew, limit = 0.2, scale = 0.5):\n",
    "        return 0.2 * np.tanh(scale * skew)\n",
    "\n",
    "    \n",
    "    def unpack_params(params):\n",
    "        theta = np.reshape(params[:(N*K)], [N, K])\n",
    "        beta = np.reshape(params[(N*K):-1], [D, K])\n",
    "        skew = skew_function(params[-1])\n",
    "#         beta = beta_o\n",
    "#         theta = theta_o\n",
    "#         skews = -0.05\n",
    "        return theta, beta, skew\n",
    "        \n",
    "    def lambertw_logpdf(loc, log_scale, skew, t):\n",
    "        scale = np.exp(log_scale)\n",
    "        u = (y - loc)/scale\n",
    "        if skew != 0: #and t > 2000:\n",
    "            u_ = u*skew\n",
    "            W = lambertw(u_)\n",
    "            z = W/skew\n",
    "#            jacobian = W/(u_*(1+W))\n",
    "            jacobian = 1./(u_+np.exp(W))\n",
    "            return norm.logpdf(z) + np.log(np.abs(jacobian)) - log_scale\n",
    "        else:\n",
    "            return norm.logpdf(u) - log_scale\n",
    "      \n",
    "    def objective(params, t):\n",
    "        theta, beta, skew = unpack_params(params)\n",
    "        loc = np.matmul(theta, beta.T)\n",
    "        return -np.sum(lambertw_logpdf(loc, np.log(1.), skew, t))\n",
    "    return objective, lambertw_logpdf, unpack_params, skew_function\n",
    "\n",
    "def callback(params, i, g):\n",
    "    if not i%100: print(i, objective(params, 0), skew_function(params[-1]), np.sum(params[:-1]), end ='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 65569.4737758 -0.115615513774 25.323055543222\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.11567427592667903"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_n = npr.randn(N,K)\n",
    "beta_n = npr.randn(D,K)\n",
    "# theta_n = theta_o\n",
    "# beta_n = beta_o\n",
    "init_params = np.concatenate([theta_n.flatten(),beta_n.flatten(),np.array([0.0001])])\n",
    "objective, lambertw_logpdf, unpack_params, skew_function = make_lambertw_routines(y)\n",
    "gradient = grad(objective)\n",
    "final_params = adam(gradient, init_params, step_size=0.01, num_iters=2000, callback = callback)\n",
    "theta_f, beta_f, skew = unpack_params(final_params) \n",
    "skew\n",
    "\n",
    "\n",
    "# Inference ends here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x111327c50>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1113f1940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loc = np.matmul(theta_f, beta_f.T)\n",
    "# z = u * scale + loc\n",
    "skews = np.arange(-0.2, 0.2, 0.01)\n",
    "mse = [np.mean((y - (u * np.exp(s * u) * scale + loc))**2) for s in skews]\n",
    "plt.plot(skews, mse, 'r-', lw=1, alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70917.875193498563"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# theta, beta, skew = unpack_params(final_params)\n",
    "# loc = np.matmul(theta_o, beta_o.T)\n",
    "# -np.sum(lambertw_logpdf(loc, np.log(1.), -0.05, 2000)) \n",
    "# skews = np.arange(-1, 1, 0.01)\n",
    "# pdf = np.copy(skews)\n",
    "\n",
    "theta, beta, skew = unpack_params(final_params)\n",
    "loc = np.matmul(theta, beta.T)\n",
    "\n",
    "for i,s in enumerate(skews):\n",
    "    pdf[i] = np.sum(lambertw_logpdf(loc, np.log(1.0), s, 5000))\n",
    "plt.plot(skews, pdf, 'r-', lw=1, alpha=0.6)\n",
    "# skews[np.where(pdf == np.max(pdf))]\n",
    "\n",
    "theta, beta, skew = unpack_params(final_params)\n",
    "loc = np.matmul(theta, beta.T)\n",
    "np.mean(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta, beta, skew = unpack_params(final_params)\n",
    "# loc = np.matmul(theta, beta.T)\n",
    "\n",
    "objective(params, 0)\n",
    "\n",
    "z_new = (u * np.exp(skew * u))\n",
    "# plt.hist(z_new.flatten(), 100, normed=True, alpha=0.2)\n",
    "# plt.hist(z.flatten(), 100, normed=True, alpha=0.2)\n",
    "y_new = u * np.exp(skew * u) * scale + loc\n",
    "# plt.show()\n",
    "print(y_new[1,])\n",
    "y[1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_params(params):\n",
    "    return params[0], params[1], params[2]\n",
    "\n",
    "def lambertw_logpdf(y, loc, log_scale, skew):\n",
    "    scale = np.exp(log_scale)\n",
    "    u = (y - loc)/scale\n",
    "    if skew != 0:\n",
    "        u_ = u*skew\n",
    "        W = lambertw(u_)\n",
    "        z = W/skew\n",
    "        jacobian = W/(u_*(1+W))\n",
    "        return norm.logpdf(z) + np.log(np.abs(jacobian)) - log_scale\n",
    "    else:\n",
    "        return norm.logpdf(u) - log_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta_o = theta = npr.randn(N,K) \n",
    "# beta_o = beta = npr.randn(D,K) \n",
    "# loc = np.matmul(theta, beta.T)\n",
    "# skews = np.arange(-1, 1, 0.01)\n",
    "# pdf = np.array([np.sum((lambertw_logpdf(y, loc, np.log(1.), skew))) for skew in skews])\n",
    "# plt.plot(skews, pdf, 'r-', lw=1, alpha=0.6)\n",
    "# skews[np.where(pdf == np.max(pdf))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lambertw_routines(y):\n",
    "    \n",
    "    def skew_function(skew, limit = 0.2, scale = 1.):\n",
    "#         return 0.15 * np.tanh(scale * skew)\n",
    "        return skew\n",
    "    \n",
    "    def unpack_params(params):\n",
    "        theta = np.reshape(params[:(N*K)], [N, K])\n",
    "        beta = np.reshape(params[(N*K):-1], [D, K])\n",
    "#         skew = skew_function(params[-1])\n",
    "        skew = -0.1\n",
    "        return theta, beta, skew\n",
    "        \n",
    "    def lambertw_logpdf(loc, log_scale, skew):\n",
    "        scale = np.exp(log_scale)\n",
    "        u = (y - loc)/scale\n",
    "        if skew != 0:\n",
    "            u_ = u*skew\n",
    "            W = lambertw(u_)\n",
    "            z = W/skew\n",
    "            jacobian = W/(u_*(1+W))\n",
    "            return gnorm.logpdf(z) + np.log(np.abs(jacobian)) - log_scale\n",
    "        else:\n",
    "            return gnorm.logpdf(u) - log_scale\n",
    "      \n",
    "    def objective(params, t):\n",
    "        theta, beta, skew = unpack_params(params)\n",
    "        loc = np.matmul(theta, beta.T)\n",
    "        return -np.sum(lambertw_logpdf(loc, np.log(1.), skew))\n",
    "    return objective, lambertw_logpdf, unpack_params, skew_function\n",
    "\n",
    "\n",
    "def callback(params, i, g):\n",
    "    if not i%100: print(i, objective(params, 0), skew_function(params[-1]), np.sum(params[:-1]), end ='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_n = npr.randn(N,K)\n",
    "beta_n = npr.randn(D,K)\n",
    "init_params = np.concatenate([theta_n.flatten(),beta_n.flatten(),np.array([-0.1])])\n",
    "objective, lambertw_logpdf, unpack_params, skew_function = make_lambertw_routines(y)\n",
    "gradient = grad(objective)\n",
    "final_params = adam(gradient, init_params, step_size=0.1, num_iters=10000, callback = callback)\n",
    "theta_f, beta_f, skew = unpack_params(final_params) \n",
    "skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_lambertw_routines(y):\n",
    "    \n",
    "    def unpack_params(params):\n",
    "        theta = anp.reshape(params[:(N*K)], [N, K])\n",
    "        beta = anp.reshape(params[(N*K):], [D, K])\n",
    "        return theta, beta\n",
    "        \n",
    "    def lambertw_logpdf(theta, beta):\n",
    "        loc = anp.matmul(theta, beta.T)\n",
    "        return (gnorm.logpdf(y, loc , 1.))\n",
    "    \n",
    "    def objective(params, t):\n",
    "        theta, beta = unpack_params(params)\n",
    "        return -anp.sum(lambertw_logpdf(theta, beta))\n",
    "    return objective, lambertw_logpdf, unpack_params\n",
    "\n",
    "\n",
    "def callback(params, i, g):\n",
    "    if not i%100: print(i, objective(params, 0), end ='\\r')\n",
    "    \n",
    "theta_n = npr.randn(N,K)\n",
    "beta_n = npr.randn(D,K)\n",
    "init_params = np.concatenate([theta_n.flatten(),beta_n.flatten()])\n",
    "objective, lambertw_logpdf, unpack_params = make_lambertw_routines(z)\n",
    "gradient = grad(objective)\n",
    "final_params = adam(gradient, init_params, step_size=0.1, num_iters=1000, callback = callback)\n",
    "theta_f, beta_f = unpack_params(final_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_new = np.matmul(theta_f, beta_f.T) + npr.randn(N,D)\n",
    "plt.hist(z_1.flatten(), 100, normed=True, alpha=0.2)\n",
    "plt.hist(z_new.flatten(), 100, normed=True, alpha=0.2)\n",
    "loc = np.mean(z_new)\n",
    "scale = np.std(z_new)\n",
    "x = np.linspace(norm.ppf(0.001, loc, scale), norm.ppf(0.999, loc, scale), 100)\n",
    "plt.plot(np.sort(z_new.flatten()), norm.pdf(np.sort(z_new.flatten()), loc, scale), 'r-', lw=1, alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_n = npr.randn(N,K)\n",
    "beta_n = npr.randn(D,K)\n",
    "init_params = np.concatenate([theta_n.flatten(),beta_n.flatten()])\n",
    "objective, lambertw_logpdf, unpack_params = make_lambertw_routines(y)\n",
    "gradient = grad(objective)\n",
    "final_params = adam(gradient, init_params, step_size=0.1, num_iters=1000, callback = callback)\n",
    "theta_f, beta_f = unpack_params(final_params) \n",
    "\n",
    "z_new = np.matmul(theta_f, beta_f.T) + npr.randn(N,D)\n",
    "plt.hist(y.flatten(), 100, normed=True, alpha=0.2)\n",
    "plt.hist(z_new.flatten(), 100, normed=True, alpha=0.2)\n",
    "loc = np.mean(z_new)\n",
    "scale = np.std(z_new)\n",
    "x = np.linspace(norm.ppf(0.001, loc, scale), norm.ppf(0.999, loc, scale), 100)\n",
    "plt.plot(np.sort(z_new.flatten()), norm.pdf(np.sort(z_new.flatten()), loc, scale), 'r-', lw=1, alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lambertw_routines(y):\n",
    "    def unpack_params(params):\n",
    "#         theta = anp.reshape(params[:(N*K)], [N, K])\n",
    "#         beta = anp.reshape(params[(N*K):-1], [D, K])\n",
    "        skew = 0.2 * anp.tanh(params[-1])\n",
    "#         skew = params[-1]\n",
    "        return theta, beta, skew\n",
    "        \n",
    "    def lambertw_logpdf(loc, log_scale, skew):\n",
    "        scale = anp.exp(log_scale)\n",
    "        u = (y - loc)/scale\n",
    "        if skew != 0:\n",
    "            u_ = u*skew\n",
    "            W = lambertw(u_)\n",
    "            z = W/skew\n",
    "            jacobian = W/(u_*(1+W))\n",
    "            return gnorm.logpdf(z) + anp.log(anp.abs(jacobian)) - log_scale\n",
    "        else:\n",
    "            return gnorm.logpdf(u) - log_scale\n",
    "      \n",
    "    def objective(params, t):\n",
    "        theta, beta, skew = unpack_params(params)\n",
    "        loc = anp.matmul(theta, beta.T)\n",
    "        return -anp.sum(lambertw_logpdf(loc, np.exp(1.), skew))\n",
    "    return objective, lambertw_logpdf, unpack_params\n",
    "\n",
    "\n",
    "def callback(params, i, g):\n",
    "    if not i%100: print(i, objective(params, 0), 0.2*anp.tanh(params[-1]), end ='\\r')\n",
    "   \n",
    "\n",
    "# theta_n = npr.randn(N,K)\n",
    "# beta_n = npr.randn(D,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params = np.concatenate([theta_n.flatten(),beta_n.flatten(),np.array([-0.1])])\n",
    "objective, lambertw_logpdf, unpack_params = make_lambertw_routines(y)\n",
    "gradient = grad(objective)\n",
    "final_params = adam(gradient, init_params, step_size=0.1, num_iters=1000, callback = callback)\n",
    "theta_f, beta_f, skew = unpack_params(final_params) \n",
    "skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = np.matmul(theta_f, beta_f.T)\n",
    "scale = 1.\n",
    "#y = u * np.exp(skew * u) * scale + loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.2 * anp.tanh(skew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.arange(-10000,10, step = 1)\n",
    "plt.plot(k, lambertw(k), 'r-', lw=1, alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(0.05 * npr.randn(100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import lambertw\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def populate_lambertw(a, b, resolution):\n",
    "    x = np.linspace(a, b, resolution * (b - a) + 1)\n",
    "    y = dict(zip(x, lambertw(x,0).real))\n",
    "    def lw(i):\n",
    "        i = int((i - a) * resolution)\n",
    "        return y[i]\n",
    "    return lw\n",
    "\n",
    "\n",
    "# xs = np.linspace(0.0, 1.0, 300)\n",
    "memoized_lambertw = populate_lambertw(-5, 5, 100)\n",
    "memoized_lambertw(5)\n",
    "# plt.plot(xs, memoized_lambert(xs))\n",
    "# plt.plot(xs, lambertw(xs).real)\n",
    "# plt.show()\n",
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambertw_(-0.38, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
