{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import autograd.numpy.random as npr\n",
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "from autograd.extend import primitive, defvjp\n",
    "from autograd.misc.optimizers import adam\n",
    "import scipy.special.lambertw as lambertw_\n",
    "import autograd.scipy.stats.norm as norm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambertw = primitive(lambda x: lambertw_(x, 0).real)\n",
    "defvjp(lambertw, \n",
    "        lambda ans, x: lambda g: g * 1./ (x + np.exp(ans)),\n",
    "        None \n",
    "      )\n",
    "def slambertw_logpdf_(y, loc, scale, skew, tol = 0.8):\n",
    "    u = (y - loc)/scale\n",
    "    if skew != 0:\n",
    "        cutoff = - tol /(np.e * skew)\n",
    "        cond = u >= cutoff if skew < 0 else u <= cutoff\n",
    "        utmp = np.where(cond, cutoff, u)\n",
    "        wc = lambertw(skew * utmp)\n",
    "        gc = 1./(np.exp(wc) + skew*utmp)\n",
    "        z = np.where(cond, wc/skew + (u - cutoff) * gc, wc/skew)\n",
    "        return norm.logpdf(z) + np.log(gc) - np.log(scale)\n",
    "    else:\n",
    "        return norm.logpdf(u) - np.log(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-921.606449087\n",
      "-1.31256485826\n",
      "-1.31303320169\n"
     ]
    }
   ],
   "source": [
    "from autograd.test_util import check_grads\n",
    "\n",
    "x = np.linspace(-10,10,20)\n",
    "obj = lambda y, loc, scale, skew: np.sum(slambertw_logpdf_(y, loc, scale, skew))\n",
    "\n",
    "print(obj(x, 0., 1., 0.2))\n",
    "g = grad(obj)\n",
    "# check grad\n",
    "print(g(1., 0., 1., 0.2))\n",
    "print((obj(1., 0., 1., 0.2) - obj(1.001, 0., 1., 0.2))/-0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sample data\n",
    "N = 1000\n",
    "D = 100\n",
    "K = 5\n",
    "npr.seed(100)\n",
    "scale = 1.\n",
    "skew = 0.05\n",
    "theta_o = theta = npr.randn(N,K) \n",
    "beta_o = beta = npr.randn(D,K)\n",
    "loc = np.matmul(theta, beta.T)\n",
    "u = npr.randn(N,D)\n",
    "y = u * np.exp(skew * u) * scale + loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lambertw_routines(y, skew_function, learn = True, fixed_skew = 0.1):\n",
    "    def unpack_params(params):\n",
    "        theta = np.reshape(params[:(N*K)], [N, K])\n",
    "        beta = np.reshape(params[(N*K):-1], [D, K])\n",
    "        skew = skew_function(params[-1]) if learn else fixed_skew\n",
    "        return theta, beta, skew\n",
    "    \n",
    "    slambertw_logpdf = lambda loc, scale, skew: slambertw_logpdf_(y, loc, scale, skew, 0.9)\n",
    "\n",
    "    def objective(params, t):\n",
    "        theta, beta, skew = unpack_params(params)\n",
    "        loc = np.matmul(theta, beta.T)\n",
    "        return -np.sum(slambertw_logpdf(loc, 1., skew))\n",
    "    \n",
    "    return objective, slambertw_logpdf, unpack_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -0.2\n",
      "400 144434.473952 -1.99999999333e-05 -0.001 -58.0398601099\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-3d01ed7c668b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_lambertw_routines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskew_identity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mfinal_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mlogpdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/autograd-1.2-py3.6.egg/autograd/misc/optimizers.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(grad, x0, callback, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0m_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_x0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/autograd-1.2-py3.6.egg/autograd/misc/optimizers.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(grad, x, callback, num_iters, step_size, b1, b2, eps)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m      \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m  \u001b[0;31m# First  moment estimate.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/autograd-1.2-py3.6.egg/autograd/misc/optimizers.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, i)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0m_x0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munflatten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0m_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0m_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/autograd-1.2-py3.6.egg/autograd/wrap_util.py\u001b[0m in \u001b[0;36mnary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0munary_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munary_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnary_op_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnary_op_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnary_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnary_operator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/autograd-1.2-py3.6.egg/autograd/differential_operators.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m         raise TypeError(\"Grad only applies to real scalar-output functions. \"\n\u001b[1;32m     27\u001b[0m                         \"Try jacobian or elementwise_grad.\")\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0munary_to_nary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/autograd-1.2-py3.6.egg/autograd/core.py\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mbackward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/autograd-1.2-py3.6.egg/autograd/core.py\u001b[0m in \u001b[0;36mbackward_pass\u001b[0;34m(g, end_node)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoposort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moutgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mingrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingrad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0moutgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_outgrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/autograd-1.2-py3.6.egg/autograd/core.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mvjp_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjp_0_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mvjp_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjp_1_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvjp_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mvjps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvjps_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0margnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/autograd-1.2-py3.6.egg/autograd/numpy/numpy_vjps.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0mdefvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;32mlambda\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m   \u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmatch_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1j\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m defvjp(anp.where, None,\n\u001b[0;32m--> 133\u001b[0;31m        \u001b[0;32mlambda\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m        lambda ans, c, x=None, y=None : lambda g: anp.where(c, anp.zeros(g.shape), g))\n\u001b[1;32m    135\u001b[0m defvjp(anp.cross, lambda ans, a, b, axisa=-1, axisb=-1, axisc=-1, axis=None : lambda g:\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/autograd-1.2-py3.6.egg/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_autograd_primitive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "skews = np.linspace(-0.2, 0.2, 17)\n",
    "logpdfs = np.copy(skews)\n",
    "\n",
    "skew_tanh = lambda skew: 0.2 * np.tanh(1e-1 * skew)\n",
    "skew_identity = lambda skew: skew\n",
    "\n",
    "def callback(params, i, g):\n",
    "    if not i%100: print(i, objective(params, 0), skew_tanh(params[-1]), params[-1], np.sum(params[:-1]), end ='\\r')\n",
    "\n",
    "# learn thetas and betas for fixed skews \n",
    "for i,s in enumerate(skews): \n",
    "    print('\\n', s)\n",
    "    npr.seed(200)\n",
    "    theta_n = npr.randn(N,K) \n",
    "    beta_n = npr.randn(D,K) \n",
    "    init_params = np.concatenate([theta_n.flatten(),beta_n.flatten(),np.array([-0.001])])\n",
    "    objective, _, unpack_params = make_lambertw_routines(y, skew_identity, False, s)\n",
    "    gradient = grad(objective)\n",
    "    final_params = adam(gradient, init_params, step_size=0.1, num_iters=1000, callback = callback)\n",
    "    logpdfs[i] = -objective(final_params, 0)\n",
    "\n",
    " # learn thetas, betas along with the skew, for verifiying if the learnt skew is correct. \n",
    "npr.seed(200)\n",
    "theta_n = npr.randn(N,K) \n",
    "beta_n = npr.randn(D,K) \n",
    "init_params = np.concatenate([theta_n.flatten(),beta_n.flatten(),np.array([-0.001])])\n",
    "objective, _, unpack_params = make_lambertw_routines(y, skew_tanh)\n",
    "gradient = grad(objective)\n",
    "final_params = adam(gradient, init_params, step_size=0.1, num_iters=1000, callback = callback)\n",
    "print(objective(final_params, 0))\n",
    "inf_logpdf = -objective(final_params, 0)\n",
    "_, _, inf_skew = unpack_params(final_params)\n",
    "\n",
    "# # Inference ends here. \n",
    "np.savez(\"logpdfs-0.8.npz\", logpdfs = logpdfs, skews = skews, inf_logpdf = inf_logpdf, inf_skew = inf_skew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10db0c588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(skews, logpdfs, 'r-x', inf_skew, inf_logpdf, 'bs', lw=1, alpha=0.6)\n",
    "plt.ylabel('Log likelihood')\n",
    "plt.xlabel('Skew')\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0)) \n",
    "plt.show()\n",
    "# plt.savefig('/Users/sakaya/lambert-paper/skew.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logpdfs', 'skews', 'inf_logpdf', 'inf_skew']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v=np.load(\"logpdfs.npz\")\n",
    "v.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def slambertw_logpdf_(y, loc, scale, skew, tol = 0.8):\n",
    "# #     u = (y - loc)/scale\n",
    "# #     if skew != 0:\n",
    "# #         cutoff = - tol * 1/(np.e * skew)\n",
    "# #         cond = u >= cutoff if skew < 0 else u <= cutoff\n",
    "# #         wc = lambertw(skew*u)\n",
    "# #         gc = 1./(np.exp(wc) + skew*u)\n",
    "# #         z = wc/skew\n",
    "        \n",
    "# #         wc[cond] = wtmp = lambertw(skew * cutoff)\n",
    "# #         gc[cond] = 1./(np.exp(wtmp) + skew*cutoff)\n",
    "# #         z[cond] = wc[cond]/skew + (u[cond] - cutoff) * gc[cond]\n",
    "        \n",
    "# #         return norm.logpdf(z) + np.log(gc) - np.log(scale)\n",
    "# #     else:\n",
    "# #         return norm.logpdf(u) - np.log(scale)\n",
    "# #def slambertw_(x, skew):\n",
    "# #     cutoff = - 0.9 * 1/(np.e * skew)\n",
    "# #     cond = x >= cutoff if skew < 0 else x <= cutoff\n",
    "# #     wc = lambertw(skew * cutoff)\n",
    "# #     gc = 1. / (np.exp(wc) + skew*cutoff)\n",
    "# #     z = lambertw(skew*x)/skew\n",
    "# #     z[cond] = wc/skew + (x[cond] - cutoff) * gc\n",
    "# #     return z\n",
    "\n",
    "# # def lambertw_logpdf_(y, loc, scale, skew):\n",
    "# #     u = (y - loc)/scale\n",
    "# #     if skew != 0:\n",
    "# #         wc = lambertw(skew*u)\n",
    "# #         gc = 1./(np.exp(wc) + skew*u)\n",
    "# #         z = wc/skew\n",
    "# # #         return norm.logpdf(z) + np.log(gc) - np.log(scale)\n",
    "# #         return gc\n",
    "# #     else:\n",
    "# #         return norm.logpdf(u) - np.log(scale)\n",
    "# lmap = precompute_lambertw(-2, 2, 100)\n",
    "# # for k, v in lmap.items():\n",
    "# #     print(k,v)\n",
    "# lmap\n",
    "# # lambertw = primitive(lambda x: lambertw_(x, 0).real)\n",
    "# # defvjp(lambertw, \n",
    "# #         lambda ans, x: lambda g: g * 1./ (x + np.exp(ans)),\n",
    "# #         None \n",
    "# #       )\n",
    "\n",
    "# # def precompute_lambertw(a, b, resolution):\n",
    "# #     x = np.linspace(a, b, resolution * (b - a) + 1)\n",
    "# #     x[x < -1/np.e] = -1/np.e\n",
    "# #     x_new = ((x - a) * resolution).astype(int)\n",
    "# #     lmap = dict(zip(x_new, lambertw(x).real))\n",
    "# #     def inner(x):\n",
    "# #           x[x < -1/np.e] = -1/np.e\n",
    "# # #         sel = ((x - a) * resolution).astype(np.int32)\n",
    "# # #         return vals[sel]\n",
    "# #     return lmap\n",
    "\n",
    "# # tabl_w0 = create_lambert_table(-2, 2, 100)\n",
    "# # xs = np.array([-0.1, 0.1, 0.4])\n",
    "# # plt.plot(xs, tabl_w0(xs))\n",
    "# # plt.plot(xs, lambertw(xs).real)\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambertw = primitive(lambda x: lambertw_(x, 0).real)\n",
    "defvjp(lambertw, \n",
    "        lambda ans, x: lambda g: g * 1./ (x + np.exp(ans)),\n",
    "        None \n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambertw(x):\n",
    "    x = np.where(x < -1/np.e, -1/np.e, x)\n",
    "    return lambertw_(x,0).real\n",
    "lambertw = primitive(lambertw)\n",
    "defvjp(lambertw, \n",
    "        lambda ans, x: lambda g: g * 1./ (x + np.exp(ans)),\n",
    "        None \n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0000000044715198"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = grad(lambertw)\n",
    "x = np.linspace(-3,3,20)\n",
    "lambertw(-1)\n",
    "# g(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.36787944, -0.36787944],\n",
       "       [-0.36787944, -0.36787944]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambertw(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambertw = primitive(lambda x: lambertw_(x, 0).real)\n",
    "defvjp(lambertw, \n",
    "        lambda ans, x: lambda g: g * 1./ (x + np.exp(ans)),\n",
    "        None \n",
    "      )\n",
    "def slambertw_logpdf_(y, loc, scale, skew, tol = 0.8):\n",
    "    u = (y - loc)/scale\n",
    "    if skew != 0:\n",
    "        cutoff = - tol /(np.e * skew)\n",
    "        cond = u >= cutoff if skew < 0 else u <= cutoff\n",
    "        utmp = np.where(cond, cutoff, u)\n",
    "        wc = lambertw(skew * utmp)\n",
    "        gc = 1./(np.exp(wc) + skew*utmp)\n",
    "        z = np.where(cond, wc/skew + (u - cutoff) * gc, wc/skew)\n",
    "        return norm.logpdf(z) + np.log(gc) - np.log(scale)\n",
    "    else:\n",
    "        return norm.logpdf(u) - np.log(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.69128123,  4.69128123,  4.69128123,  4.69128123,  4.69128123,\n",
       "        4.69128123,  4.69128123,  4.69128123,  3.78007789,  1.27716755,\n",
       "        0.82942925,  0.62670937,  0.50833241,  0.42982949,  0.37358055,\n",
       "        0.33111166,  0.29780977,  0.27093561,  0.2487541 ,  0.23010984])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = x\n",
    "skew = 0.2\n",
    "cutoff = - 0.9 /(np.e * skew)\n",
    "cond = u >= cutoff if skew < 0 else u <= cutoff\n",
    "utmp = np.where(cond, cutoff, u)\n",
    "wc = lambertw(utmp * skew)\n",
    "gc = 1./(np.exp(wc) + skew*utmp)\n",
    "gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = grad(lambertw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.69128123,  4.69128123,  4.69128123,  4.69128123,  4.69128123,\n",
       "        4.69128123,  4.69128123,  4.69128123,  3.78007789,  1.27716755,\n",
       "        0.82942925,  0.62670937,  0.50833241,  0.42982949,  0.37358055,\n",
       "        0.33111166,  0.29780977,  0.27093561,  0.2487541 ,  0.23010984])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([g(u * skew) for u in utmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
